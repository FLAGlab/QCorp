{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba913802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values(board, decimals = 2):\n",
    "    for i in range(0, len(board)):\n",
    "        print('--------------------------------------------------------------------------------------------------')\n",
    "        out = '| '\n",
    "        for j in range(0, len(board[0])):\n",
    "            value = 0\n",
    "            if type(board[i][j]) == str:\n",
    "                value = board[i][j]\n",
    "            else:\n",
    "                value = round(board[i][j],decimals)\n",
    "            out += str(value).ljust(7) + ' | '\n",
    "        print(out)\n",
    "    print('--------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b928c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "class Gridworld:\n",
    "    #Dimensions[rows,cols]\n",
    "    #Each cell element [row,col,value]\n",
    "    def __init__(self, dimensions=[10,10], cells={}, initial_state=None, actions=['up','down','left','right']):\n",
    "        self.dimensions = dimensions\n",
    "        self.actions = actions\n",
    "        self.cells = cells\n",
    "        self.state_actions = self.define_actions()\n",
    "        self.init_state(initial_state)\n",
    "        \n",
    "    def define_actions(self):\n",
    "        state_actions = {}\n",
    "        for row in range(self.dimensions[0]):\n",
    "            for col in range(self.dimensions[1]):\n",
    "                state = (row, col)\n",
    "                if state in self.cells:\n",
    "                    actions = self.actions.copy()\n",
    "                    if 'e' in self.cells[state]:\n",
    "                        actions.append('exit')\n",
    "                    if 'l' in self.cells[state]:\n",
    "                        actions.remove('left')\n",
    "                    if 't' in self.cells[state]:\n",
    "                        actions.remove('up')\n",
    "                    if 'r' in self.cells[state]:\n",
    "                        actions.remove('right')\n",
    "                    if 'b' in self.cells[state]:\n",
    "                        actions.remove('down')\n",
    "                    state_actions[state] = actions\n",
    "                else:\n",
    "                    state_actions[state] = self.actions \n",
    "        return state_actions\n",
    "        \n",
    "    def get_board(self):\n",
    "        return self.board\n",
    "        \n",
    "    def get_current_state(self):\n",
    "        return self.current_state\n",
    "    \n",
    "    def get_possible_actions(self, state=(0,0)):\n",
    "        return self.state_actions[state]\n",
    "    \n",
    "    def do_action(self, action, state = None):\n",
    "        current_state = self.current_state\n",
    "        reward = 0\n",
    "        if state != None:\n",
    "            current_state = state\n",
    "        new_state = ()\n",
    "        if(action=='up'):\n",
    "            new_state=(current_state[0]-1,current_state[1])\n",
    "        elif(action=='down'):\n",
    "            new_state=(current_state[0]+1,current_state[1])\n",
    "        elif(action=='left'):\n",
    "            new_state=(current_state[0],current_state[1]-1)\n",
    "        elif(action=='right'):\n",
    "            new_state=(current_state[0],current_state[1]+1)\n",
    "        elif(action=='exit'):\n",
    "            new_state=(current_state[0],current_state[1])\n",
    "            return [100, new_state]\n",
    "        \n",
    "        return [-1, new_state]\n",
    "    \n",
    "    def init_state(self, initial_state=None):\n",
    "        if initial_state:\n",
    "            self.initial_state = initial_state\n",
    "            self.current_state = initial_state\n",
    "        else:\n",
    "            new_initial_state = random.choice(list(self.state_actions.keys()))\n",
    "            self.initial_state = new_initial_state\n",
    "            self.current_state = new_initial_state\n",
    "        \n",
    "    def is_terminal(self, action):\n",
    "        if action == 'exit':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38c6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "    #Dimensions[rows,cols]\n",
    "    #Each cell element [row,col,value]\n",
    "    def __init__(self, mdp, discount=0.9, alpha=0.5, iterations=False, epsilon=0.9):\n",
    "        # Mdp is equivalent to env\n",
    "        self.mdp = mdp\n",
    "        self.alpha = alpha\n",
    "        self.discount = discount\n",
    "        self.iterations = iterations\n",
    "        self.epsilon = epsilon\n",
    "        self.q = {}\n",
    "        state_actions = self.mdp.state_actions\n",
    "        for state in state_actions.keys():\n",
    "            for action in state_actions[state]:\n",
    "                self.q[(state[0],state[1],action)] = 0\n",
    "\n",
    "    def run_episode(self):\n",
    "        last_action = ''\n",
    "        while not self.mdp.is_terminal(last_action):\n",
    "            state1 = self.mdp.current_state\n",
    "            action = self.choose_action(state1)\n",
    "            action1 = action[0]\n",
    "            last_action = action1\n",
    "            res_do_action = self.mdp.do_action(action[0], self.mdp.current_state)\n",
    "            state2 = res_do_action[1]\n",
    "            action2 = self.choose_best_action(state2)[0]\n",
    "            reward = res_do_action[0]\n",
    "            self.action_function(state1,action1,reward,state2,action2)\n",
    "            self.mdp.current_state = state2\n",
    "    \n",
    "    def run_value_iteration(self):\n",
    "        # Begins at iteration 2 because first iteration is initializing rewards\n",
    "        converge = 0\n",
    "        i = 1\n",
    "        while self.iterations >= i:\n",
    "            i += 1\n",
    "            self.mdp.init_state()\n",
    "            self.run_episode()\n",
    "        print(\"Total iterations: \" + str(i))\n",
    "    \n",
    "    def action_function(self,state1,action1,reward,state2,action2):\n",
    "        self.q[(state1[0], state1[1], action1)] = (1-self.alpha)*self.q[(state1[0], state1[1], action1)] + self.alpha*(reward + self.discount*self.q[(state2[0], state2[1], action2)])\n",
    "    \n",
    "    def choose_best_action(self, state):\n",
    "        possible_actions = self.mdp.get_possible_actions(state)\n",
    "        best_actions = []\n",
    "        best_q_value = -9999999\n",
    "        for action in possible_actions:\n",
    "            if len(best_actions) == 0:\n",
    "                best_actions.append(action)\n",
    "                best_q_value = self.q[(state[0], state[1], action)]\n",
    "            else:\n",
    "                if best_q_value == self.q[(state[0], state[1], action)]:\n",
    "                    best_actions.append(action)\n",
    "                elif best_q_value < self.q[(state[0], state[1], action)]:\n",
    "                    best_actions = [action]\n",
    "                    best_q_value = self.q[(state[0], state[1], action)]\n",
    "                    \n",
    "        best_action = random.choice(best_actions)\n",
    "        return [best_action, best_action]\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        possible_actions = self.mdp.get_possible_actions(state).copy()\n",
    "        best_actions = []\n",
    "        best_q_value = -9999999\n",
    "        for action in possible_actions:\n",
    "            if len(best_actions) == 0:\n",
    "                best_actions.append(action)\n",
    "                best_q_value = self.q[(state[0], state[1], action)]\n",
    "            else:\n",
    "                if best_q_value == self.q[(state[0], state[1], action)]:\n",
    "                    best_actions.append(action)\n",
    "                elif best_q_value < self.q[(state[0], state[1], action)]:\n",
    "                    best_actions = [action]\n",
    "                    best_q_value = self.q[(state[0], state[1], action)]\n",
    "                    \n",
    "        best_action = random.choice(best_actions)\n",
    "        if random.random() < (1-self.epsilon) :\n",
    "            return [best_action, best_action]\n",
    "        else:\n",
    "            possible_actions.remove(best_action)\n",
    "            return [random.choice(possible_actions), best_action]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bb7330",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations: 10001\n"
     ]
    }
   ],
   "source": [
    "grid = Gridworld(cells={(0, 0): 'lt', (0, 1): 't', (0, 3): 't', (0, 4): 'tr', (0, 5): 'lt', (0, 6): 't', (0, 7): 't', (0, 8): 't', (0, 9): 'tr', (1, 0): 'l', (1, 4): 'r', (1, 5): 'l', (1, 9): 'r', (2, 0): 'l', (2, 9): 'r', (3, 0): 'l', (3, 4): 'r', (3, 5): 'l', (3, 9): 'r', (4, 0): 'lb', (4, 4): 'rb', (4, 5): 'lb', (4, 9): 'rb', (5, 0): 'lt', (5, 1): 't', (5, 3): 't', (5, 4): 'tr', (5, 5): 'tl', (5, 6): 't', (5, 8): 't', (5, 9): 'tr', (6, 0): 'l', (6, 4):'r' , (6, 5): 'l', (6, 9): 'r', (7, 0): 'l', (7, 9): 'r', (8, 0): 'l',(8, 4): 'r', (8, 5): 'l', (8, 9): 'r', (9, 0): 'lb', (9, 1): 'b', (9, 2): 'b', (9, 3): 'b', (9, 4): 'rb', (9, 5): 'lb', (9, 6): 'b', (9, 7): 'b', (9, 8): 'b', (9, 9): 'rb', (0, 2): 'te'},\n",
    "                 dimensions = [10,10])\n",
    "\n",
    "iteration = QLearning(grid, discount = 0.7, alpha=0.1, iterations = 10000, epsilon=0.1)\n",
    "iteration.run_value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be7dfe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------\n",
      "| 161.63  | 232.33  | 333.33  | 232.33  | 161.38  | 24.39   | 16.07   | 10.25   | 6.18    | 3.32    | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 112.14  | 161.63  | 232.33  | 161.63  | 112.14  | 36.28   | 24.39   | 16.07   | 10.25   | 6.18    | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 77.5    | 112.14  | 161.63  | 112.14  | 77.5    | 53.25   | 36.28   | 24.39   | 16.07   | 10.25   | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 53.25   | 77.5    | 112.14  | 77.5    | 53.25   | 36.28   | 24.39   | 16.07   | 10.25   | 6.18    | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 36.27   | 53.25   | 77.5    | 53.25   | 36.27   | 24.39   | 16.07   | 10.25   | 6.18    | 3.32    | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 24.39   | 36.28   | 53.25   | 36.28   | 24.39   | 1.33    | 3.32    | 6.18    | 3.32    | 1.33    | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 16.07   | 24.39   | 36.28   | 24.39   | 16.07   | 3.32    | 1.33    | 3.32    | 1.33    | -0.07   | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 10.25   | 16.07   | 24.39   | 16.07   | 10.25   | 6.18    | 3.32    | 1.33    | -0.07   | -1.05   | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 6.18    | 10.25   | 16.07   | 10.25   | 6.18    | 3.32    | 1.33    | -0.07   | -1.05   | -1.73   | \n",
      "--------------------------------------------------------------------------------------------------\n",
      "| 3.32    | 6.18    | 10.25   | 6.18    | 3.32    | 1.33    | -0.07   | -1.05   | -1.73   | -2.21   | \n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "board = np.full((10, 10), float('-inf'))\n",
    "for (x, y, action), value in iteration.q.items():\n",
    "    board[x][y] = max(board[x][y], value)\n",
    "show_values(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1c6116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x    y  up     down    left    right    exit\n",
      "---  ---  -----  ------  ------  -------  ------\n",
      "  0    0  -      55.5    -       161.5    -\n",
      "  0    1  -      112.0   112.0   232.5    -\n",
      "  0    2  -      161.5   161.5   161.5    333.5\n",
      "  0    3  -      112.0   232.5   81.0     -\n",
      "  0    4  -      77.5    161.5   -        -\n",
      "  0    5  -      24.5    -       6.5      -\n",
      "  0    6  -      16.0    8.5     1.0      -\n",
      "  0    7  -      10.5    5.0     0.5      -\n",
      "  0    8  -      6.0     2.5     -0.5     -\n",
      "  0    9  -      3.5     2.5     -        -\n",
      "  1    0  27.5   27.5    -       112.0    -\n",
      "  1    1  161.5  71.0    70.5    140.0    -\n",
      "  1    2  232.5  112.0   112.0   112.0    -\n",
      "  1    3  161.5  77.5    161.5   77.5     -\n",
      "  1    4  77.5   48.0    112.0   -        -\n",
      "  1    5  16.0   36.5    -       16.0     -\n",
      "  1    6  9.0    22.5    24.5    9.5      -\n",
      "  1    7  2.5    9.0     16.0    2.5      -\n",
      "  1    8  1.0    10.5    2.0     0.5      -\n",
      "  1    9  0.5    6.0     2.0     -        -\n",
      "  2    0  34.0   21.0    -       77.5     -\n",
      "  2    1  61.0   43.5    39.5    112.0    -\n",
      "  2    2  161.5  77.5    77.5    77.5     -\n",
      "  2    3  112.0  53.5    112.0   53.5     -\n",
      "  2    4  77.5   36.5    77.5    36.5     -\n",
      "  2    5  24.5   24.5    53.5    24.5     -\n",
      "  2    6  16.0   16.0    36.5    16.0     -\n",
      "  2    7  10.0   10.0    24.5    10.0     -\n",
      "  2    8  6.0    6.0     16.0    6.0      -\n",
      "  2    9  2.0    2.5     10.5    -        -\n",
      "  3    0  42.0   11.5    -       53.5     -\n",
      "  3    1  59.5   33.5    26.5    77.5     -\n",
      "  3    2  112.0  53.5    53.5    53.5     -\n",
      "  3    3  77.5   35.0    70.5    34.5     -\n",
      "  3    4  53.5   18.0    41.0    -        -\n",
      "  3    5  36.5   10.5    -       12.5     -\n",
      "  3    6  24.5   7.0     22.0    8.5      -\n",
      "  3    7  16.0   6.0     15.5    6.0      -\n",
      "  3    8  10.5   0.5     3.0     0.0      -\n",
      "  3    9  6.0    -1.0    2.5     -        -\n",
      "  4    0  36.5   -       -       16.5     -\n",
      "  4    1  29.5   16.0    13.5    53.5     -\n",
      "  4    2  77.5   36.5    36.5    36.5     -\n",
      "  4    3  53.5   18.0    42.0    14.5     -\n",
      "  4    4  23.5   -       36.5    -        -\n",
      "  4    5  24.5   -       -       5.5      -\n",
      "  4    6  16.0   -1.5    5.5     2.5      -\n",
      "  4    7  10.5   3.5     10.0    3.5      -\n",
      "  4    8  1.0    0.0     6.0     -1.0     -\n",
      "  4    9  1.5    -       3.5     -        -\n",
      "  5    0  -      6.0     -       24.5     -\n",
      "  5    1  -      14.5    11.0    36.5     -\n",
      "  5    2  53.5   24.5    24.5    24.5     -\n",
      "  5    3  -      13.5    36.5    13.5     -\n",
      "  5    4  -      7.0     24.5    -        -\n",
      "  5    5  -      1.5     -       0.5      -\n",
      "  5    6  -      -1.0    -2.0    3.5      -\n",
      "  5    7  6.0    1.0     1.0     1.0      -\n",
      "  5    8  -      -0.5    3.5     -0.5     -\n",
      "  5    9  -      -1.5    1.5     -        -\n",
      "  6    0  1.5    3.5     -       16.0     -\n",
      "  6    1  19.0   7.5     8.5     24.5     -\n",
      "  6    2  36.5   16.0    16.0    16.0     -\n",
      "  6    3  24.5   10.5    24.5    10.5     -\n",
      "  6    4  13.0   2.0     16.0    -        -\n",
      "  6    5  -1.0   3.5     -       -0.5     -\n",
      "  6    6  -0.5   1.5     -1.0    -1.5     -\n",
      "  6    7  3.5    -1.5    -1.5    -2.0     -\n",
      "  6    8  -1.5   -2.0    1.5     -2.0     -\n",
      "  6    9  0.0    -2.5    -1.0    -        -\n",
      "  7    0  4.5    1.5     -       10.5     -\n",
      "  7    1  16.0   3.5     1.5     4.0      -\n",
      "  7    2  24.5   10.0    10.0    10.0     -\n",
      "  7    3  16.0   6.0     16.0    6.0      -\n",
      "  7    4  10.0   3.5     10.5    3.5      -\n",
      "  7    5  1.5    1.5     6.0     1.5      -\n",
      "  7    6  0.0    0.0     3.5     0.0      -\n",
      "  7    7  1.0    -1.0    1.5     -1.0     -\n",
      "  7    8  -0.5   -2.0    0.0     -2.0     -\n",
      "  7    9  -1.5   -2.5    -1.0    -        -\n",
      "  8    0  0.5    -0.5    -       6.0      -\n",
      "  8    1  6.0    -0.5    0.0     10.5     -\n",
      "  8    2  16.0   5.5     5.5     5.0      -\n",
      "  8    3  10.5   2.0     9.5     2.5      -\n",
      "  8    4  4.0    0.0     6.0     -        -\n",
      "  8    5  3.5    -1.0    -       -0.5     -\n",
      "  8    6  1.5    -2.0    -0.5    -2.0     -\n",
      "  8    7  0.0    -2.0    -2.0    -2.0     -\n",
      "  8    8  -1.0   -2.5    -2.0    -2.5     -\n",
      "  8    9  -1.5   -2.5    -2.0    -        -\n",
      "  9    0  1.0    -       -       3.5      -\n",
      "  9    1  5.0    -       0.0     6.0      -\n",
      "  9    2  10.5   -       2.5     1.5      -\n",
      "  9    3  6.0    -       3.0     0.0      -\n",
      "  9    4  3.5    -       1.0     -        -\n",
      "  9    5  1.5    -       -       -1.5     -\n",
      "  9    6  0.0    -       -1.5    -2.5     -\n",
      "  9    7  -1.0   -       -2.0    -2.5     -\n",
      "  9    8  -1.5   -       -2.5    -2.5     -\n",
      "  9    9  -2.0   -       -2.5    -        -\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "my_dict = iteration.q\n",
    "\n",
    "# Create a dictionary to store the table data\n",
    "table_data = {}\n",
    "\n",
    "# Iterate through the keys in the dictionary\n",
    "for key in my_dict.keys():\n",
    "    # Extract x, y, and action from the key\n",
    "    x, y, action = key\n",
    "\n",
    "    # If x, y pair is not in table_data, create a new row with x, y as the key\n",
    "    if (x, y) not in table_data:\n",
    "        table_data[(x, y)] = {}\n",
    "\n",
    "    # Set the value of the action column in the table data\n",
    "    table_data[(x, y)][action] = round(my_dict[key]*2)/2\n",
    "\n",
    "# Convert the dictionary to a list of rows\n",
    "table_rows = []\n",
    "for key, value in table_data.items():\n",
    "    row = list(key) + [value.get('up', '-'), value.get('down', '-'), value.get('left', '-'), value.get('right', '-'), value.get('exit', '-')]\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Print the table using tabulate\n",
    "print(tabulate(table_rows, headers=['x', 'y', 'up','down','left','right','exit']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
